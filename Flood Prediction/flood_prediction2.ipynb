{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns  \n",
    "from matplotlib import pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 42\n",
    "N_SPLITS = 5\n",
    "N_REPEATS = 1\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,KFold, StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the original dataset into its respective statistical features and use only those features,\n",
    "#### as we observed in our [previous notebook](https://www.kaggle.com/code/shlokshivkar/s4e5-flood-eda-featengg-stats-beginnerfriendly) that using only these features we obtain the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cols = df_train.drop(columns='FloodProbability').columns\n",
    "cols_test = df_test.drop(columns='id').columns\n",
    "\n",
    "def add_stat_features(df, cols):\n",
    "    df['Sum'] = df[cols].sum(axis = 1)   \n",
    "    df['Mean'] = 0.1*df[cols].mean(axis = 1)\n",
    "    df['Max'] = df[cols].max(axis = 1)\n",
    "    df['Min'] = df[cols].min(axis = 1)\n",
    "    df['Median'] = 0.1*df[cols].median(axis = 1)\n",
    "    df['Std'] = df[cols].std(axis = 1)\n",
    "    quantiles = df[cols].quantile([0.25, 0.75], axis=1)\n",
    "    df['q1'] = quantiles.loc[0.25]\n",
    "    df['q3'] = quantiles.loc[0.75]\n",
    "    df['IQR'] = df['q3'] - df['q1']\n",
    "    df['ptp'] = df[cols].apply(lambda x: np.ptp(x), axis=1)  #ptp stands for peak to peak and it is basically [max - min]\n",
    "    \n",
    "    return df\n",
    "\n",
    "add_stat_features(df_train, cols)\n",
    "add_stat_features(df_test, cols_test)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('statistical_train.csv')\n",
    "df_test = pd.read_csv('statistical_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'FloodProbability'\n",
    "NUMERIC_COLS = df_train.select_dtypes(include='number').columns.drop(TARGET).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns='FloodProbability')\n",
    "y = df_train.FloodProbability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#optuna for XGB\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'reg_alpha': trial.suggest_int('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_int('reg_lambda', 0, 10),\n",
    "        'gamma': trial.suggest_int('gamma', 0, 10),\n",
    "        'random_state': 42,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return r2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 00:24:17,251] A new study created in memory with name: no-name-5f9a7ec4-f1ea-468a-960c-c7d4b3e35d8a\n",
      "[I 2024-05-16 00:24:28,550] Trial 0 finished with value: 0.8564611316868064 and parameters: {'n_estimators': 232, 'max_depth': 10, 'learning_rate': 0.22354989617017423, 'subsample': 0.8994866520966754, 'colsample_bytree': 0.7650420316285818, 'min_child_weight': 8, 'reg_alpha': 8, 'reg_lambda': 8, 'gamma': 3}. Best is trial 0 with value: 0.8564611316868064.\n",
      "[I 2024-05-16 00:24:44,720] Trial 1 finished with value: 0.8129018117357888 and parameters: {'n_estimators': 355, 'max_depth': 5, 'learning_rate': 0.12321391008440057, 'subsample': 0.34839667732429735, 'colsample_bytree': 0.23863132675401907, 'min_child_weight': 9, 'reg_alpha': 10, 'reg_lambda': 0, 'gamma': 6}. Best is trial 0 with value: 0.8564611316868064.\n",
      "[I 2024-05-16 00:25:22,050] Trial 2 finished with value: 0.8085778117934843 and parameters: {'n_estimators': 950, 'max_depth': 9, 'learning_rate': 0.2559252001653466, 'subsample': 0.8518112991850603, 'colsample_bytree': 0.1984295111735902, 'min_child_weight': 2, 'reg_alpha': 3, 'reg_lambda': 1, 'gamma': 5}. Best is trial 0 with value: 0.8564611316868064.\n",
      "[I 2024-05-16 00:25:45,783] Trial 3 finished with value: 0.8204546785094713 and parameters: {'n_estimators': 618, 'max_depth': 7, 'learning_rate': 0.05342255170708449, 'subsample': 0.22705656680478395, 'colsample_bytree': 0.17740903445547063, 'min_child_weight': 1, 'reg_alpha': 0, 'reg_lambda': 5, 'gamma': 4}. Best is trial 0 with value: 0.8564611316868064.\n",
      "[W 2024-05-16 00:25:47,077] Trial 4 failed with parameters: {'n_estimators': 706, 'max_depth': 8, 'learning_rate': 0.2843565406542087, 'subsample': 0.2095103654395879, 'colsample_bytree': 0.8020833144688292, 'min_child_weight': 1, 'reg_alpha': 3, 'reg_lambda': 2, 'gamma': 4} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13024\\237171883.py\", line 20, in objective\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 2051, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2024-05-16 00:25:47,079] Trial 4 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [92], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m study_XGB \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstudy_XGB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn [91], line 20\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      5\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1000\u001b[39m),\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     17\u001b[0m }\n\u001b[0;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     22\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1090\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1079\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m (\n\u001b[0;32m   1082\u001b[0m     model,\n\u001b[0;32m   1083\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1088\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1089\u001b[0m )\n\u001b[1;32m-> 1090\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     _check_call(\n\u001b[1;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study_XGB = optuna.create_study(direction='maximize')\n",
    "study_XGB.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_params = {'n_estimators': 111,\n",
    "            'max_depth': 8,\n",
    "            'learning_rate': 0.21377892857200032,\n",
    "            'subsample': 0.976892966708101,\n",
    "            'colsample_bytree': 0.984880269641595,\n",
    "            'min_child_weight': 4,\n",
    "            'reg_alpha': 2,\n",
    "            'reg_lambda': 3,\n",
    "            'gamma': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#optuna for LGB\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'reg_alpha': trial.suggest_int('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_int('reg_lambda', 0, 10),\n",
    "        'gamma': trial.suggest_int('gamma', 0, 10),\n",
    "        'random_state': 42,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    model = LGBMRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_lgb = optuna.create_study(direction='maximize')\n",
    "study_lgb.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_params = {'n_estimators': 544,\n",
    " 'max_depth': 7,\n",
    " 'learning_rate': 0.09078206198624092,\n",
    " 'subsample': 0.37888095128502086,\n",
    " 'colsample_bytree': 0.872126903661994,\n",
    " 'min_child_weight': 4,\n",
    " 'reg_alpha': 1,\n",
    " 'reg_lambda': 1,\n",
    " 'verbose': -1,\n",
    " 'gamma': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#optuna for CAT\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
    "        'random_state': 42,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    \n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)   \n",
    "    \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_cat = optuna.create_study(direction='maximize')\n",
    "study_cat.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_params = {'n_estimators': 575,\n",
    " 'max_depth': 9,\n",
    " 'learning_rate': 0.08349124099475252,\n",
    " 'subsample': 0.6660595433113499}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 525\n",
      "[LightGBM] [Info] Number of data points in the train set: 894365, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.504480\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "0:\tlearn: 0.0474552\ttotal: 180ms\tremaining: 1m 43s\n",
      "1:\tlearn: 0.0442277\ttotal: 347ms\tremaining: 1m 39s\n",
      "2:\tlearn: 0.0412944\ttotal: 524ms\tremaining: 1m 39s\n",
      "3:\tlearn: 0.0386595\ttotal: 702ms\tremaining: 1m 40s\n",
      "4:\tlearn: 0.0362856\ttotal: 871ms\tremaining: 1m 39s\n",
      "5:\tlearn: 0.0341428\ttotal: 1.03s\tremaining: 1m 38s\n",
      "6:\tlearn: 0.0322280\ttotal: 1.19s\tremaining: 1m 36s\n",
      "7:\tlearn: 0.0305378\ttotal: 1.53s\tremaining: 1m 48s\n",
      "8:\tlearn: 0.0290287\ttotal: 1.81s\tremaining: 1m 53s\n",
      "9:\tlearn: 0.0276933\ttotal: 2s\tremaining: 1m 53s\n",
      "10:\tlearn: 0.0265109\ttotal: 2.23s\tremaining: 1m 54s\n",
      "11:\tlearn: 0.0254684\ttotal: 2.44s\tremaining: 1m 54s\n",
      "12:\tlearn: 0.0245544\ttotal: 2.66s\tremaining: 1m 55s\n",
      "13:\tlearn: 0.0237581\ttotal: 2.85s\tremaining: 1m 54s\n",
      "14:\tlearn: 0.0230676\ttotal: 3.04s\tremaining: 1m 53s\n",
      "15:\tlearn: 0.0224582\ttotal: 3.37s\tremaining: 1m 57s\n",
      "16:\tlearn: 0.0219403\ttotal: 3.65s\tremaining: 1m 59s\n",
      "17:\tlearn: 0.0214840\ttotal: 3.87s\tremaining: 1m 59s\n",
      "18:\tlearn: 0.0210877\ttotal: 4.04s\tremaining: 1m 58s\n",
      "19:\tlearn: 0.0207481\ttotal: 4.23s\tremaining: 1m 57s\n",
      "20:\tlearn: 0.0204566\ttotal: 4.38s\tremaining: 1m 55s\n",
      "21:\tlearn: 0.0202084\ttotal: 4.57s\tremaining: 1m 54s\n",
      "22:\tlearn: 0.0199964\ttotal: 4.73s\tremaining: 1m 53s\n",
      "23:\tlearn: 0.0198161\ttotal: 4.91s\tremaining: 1m 52s\n",
      "24:\tlearn: 0.0196556\ttotal: 5.08s\tremaining: 1m 51s\n",
      "25:\tlearn: 0.0195215\ttotal: 5.26s\tremaining: 1m 50s\n",
      "26:\tlearn: 0.0194055\ttotal: 5.42s\tremaining: 1m 50s\n",
      "27:\tlearn: 0.0193076\ttotal: 5.61s\tremaining: 1m 49s\n",
      "28:\tlearn: 0.0192212\ttotal: 5.82s\tremaining: 1m 49s\n",
      "29:\tlearn: 0.0191431\ttotal: 6.01s\tremaining: 1m 49s\n",
      "30:\tlearn: 0.0190740\ttotal: 6.17s\tremaining: 1m 48s\n",
      "31:\tlearn: 0.0190221\ttotal: 6.35s\tremaining: 1m 47s\n",
      "32:\tlearn: 0.0189708\ttotal: 6.51s\tremaining: 1m 46s\n",
      "33:\tlearn: 0.0189321\ttotal: 6.68s\tremaining: 1m 46s\n",
      "34:\tlearn: 0.0188927\ttotal: 6.85s\tremaining: 1m 45s\n",
      "35:\tlearn: 0.0188642\ttotal: 7.02s\tremaining: 1m 45s\n",
      "36:\tlearn: 0.0188346\ttotal: 7.17s\tremaining: 1m 44s\n",
      "37:\tlearn: 0.0188077\ttotal: 7.36s\tremaining: 1m 44s\n",
      "38:\tlearn: 0.0187876\ttotal: 7.57s\tremaining: 1m 44s\n",
      "39:\tlearn: 0.0187704\ttotal: 7.84s\tremaining: 1m 44s\n",
      "40:\tlearn: 0.0187536\ttotal: 7.98s\tremaining: 1m 43s\n",
      "41:\tlearn: 0.0187398\ttotal: 8.15s\tremaining: 1m 43s\n",
      "42:\tlearn: 0.0187258\ttotal: 8.3s\tremaining: 1m 42s\n",
      "43:\tlearn: 0.0187146\ttotal: 8.45s\tremaining: 1m 42s\n",
      "44:\tlearn: 0.0187044\ttotal: 8.61s\tremaining: 1m 41s\n",
      "45:\tlearn: 0.0186954\ttotal: 8.78s\tremaining: 1m 40s\n",
      "46:\tlearn: 0.0186880\ttotal: 8.91s\tremaining: 1m 40s\n",
      "47:\tlearn: 0.0186807\ttotal: 9.08s\tremaining: 1m 39s\n",
      "48:\tlearn: 0.0186718\ttotal: 9.23s\tremaining: 1m 39s\n",
      "49:\tlearn: 0.0186650\ttotal: 9.4s\tremaining: 1m 38s\n",
      "50:\tlearn: 0.0186583\ttotal: 9.56s\tremaining: 1m 38s\n",
      "51:\tlearn: 0.0186522\ttotal: 9.71s\tremaining: 1m 37s\n",
      "52:\tlearn: 0.0186472\ttotal: 9.86s\tremaining: 1m 37s\n",
      "53:\tlearn: 0.0186412\ttotal: 10s\tremaining: 1m 36s\n",
      "54:\tlearn: 0.0186363\ttotal: 10.2s\tremaining: 1m 36s\n",
      "55:\tlearn: 0.0186317\ttotal: 10.3s\tremaining: 1m 35s\n",
      "56:\tlearn: 0.0186275\ttotal: 10.5s\tremaining: 1m 35s\n",
      "57:\tlearn: 0.0186235\ttotal: 10.6s\tremaining: 1m 34s\n",
      "58:\tlearn: 0.0186192\ttotal: 10.8s\tremaining: 1m 34s\n",
      "59:\tlearn: 0.0186157\ttotal: 11s\tremaining: 1m 34s\n",
      "60:\tlearn: 0.0186123\ttotal: 11.1s\tremaining: 1m 33s\n",
      "61:\tlearn: 0.0186087\ttotal: 11.3s\tremaining: 1m 33s\n",
      "62:\tlearn: 0.0186061\ttotal: 11.4s\tremaining: 1m 32s\n",
      "63:\tlearn: 0.0186036\ttotal: 11.6s\tremaining: 1m 32s\n",
      "64:\tlearn: 0.0185990\ttotal: 12s\tremaining: 1m 34s\n",
      "65:\tlearn: 0.0185954\ttotal: 12.2s\tremaining: 1m 34s\n",
      "66:\tlearn: 0.0185928\ttotal: 12.4s\tremaining: 1m 33s\n",
      "67:\tlearn: 0.0185907\ttotal: 12.6s\tremaining: 1m 33s\n",
      "68:\tlearn: 0.0185891\ttotal: 12.8s\tremaining: 1m 33s\n",
      "69:\tlearn: 0.0185867\ttotal: 13s\tremaining: 1m 33s\n",
      "70:\tlearn: 0.0185839\ttotal: 13.2s\tremaining: 1m 33s\n",
      "71:\tlearn: 0.0185822\ttotal: 13.3s\tremaining: 1m 33s\n",
      "72:\tlearn: 0.0185797\ttotal: 13.5s\tremaining: 1m 32s\n",
      "73:\tlearn: 0.0185773\ttotal: 13.7s\tremaining: 1m 33s\n",
      "74:\tlearn: 0.0185757\ttotal: 14s\tremaining: 1m 33s\n",
      "75:\tlearn: 0.0185742\ttotal: 14.2s\tremaining: 1m 33s\n",
      "76:\tlearn: 0.0185720\ttotal: 14.3s\tremaining: 1m 32s\n",
      "77:\tlearn: 0.0185699\ttotal: 14.5s\tremaining: 1m 32s\n",
      "78:\tlearn: 0.0185686\ttotal: 14.7s\tremaining: 1m 32s\n",
      "79:\tlearn: 0.0185660\ttotal: 14.9s\tremaining: 1m 32s\n",
      "80:\tlearn: 0.0185652\ttotal: 15.1s\tremaining: 1m 31s\n",
      "81:\tlearn: 0.0185634\ttotal: 15.5s\tremaining: 1m 32s\n",
      "82:\tlearn: 0.0185620\ttotal: 15.7s\tremaining: 1m 32s\n",
      "83:\tlearn: 0.0185609\ttotal: 15.9s\tremaining: 1m 32s\n",
      "84:\tlearn: 0.0185588\ttotal: 16.1s\tremaining: 1m 32s\n",
      "85:\tlearn: 0.0185566\ttotal: 16.3s\tremaining: 1m 32s\n",
      "86:\tlearn: 0.0185551\ttotal: 16.5s\tremaining: 1m 32s\n",
      "87:\tlearn: 0.0185531\ttotal: 16.7s\tremaining: 1m 32s\n",
      "88:\tlearn: 0.0185520\ttotal: 16.8s\tremaining: 1m 32s\n",
      "89:\tlearn: 0.0185511\ttotal: 17.2s\tremaining: 1m 32s\n",
      "90:\tlearn: 0.0185500\ttotal: 17.4s\tremaining: 1m 32s\n",
      "91:\tlearn: 0.0185491\ttotal: 17.6s\tremaining: 1m 32s\n",
      "92:\tlearn: 0.0185484\ttotal: 17.8s\tremaining: 1m 32s\n",
      "93:\tlearn: 0.0185476\ttotal: 18s\tremaining: 1m 32s\n",
      "94:\tlearn: 0.0185465\ttotal: 18.2s\tremaining: 1m 31s\n",
      "95:\tlearn: 0.0185452\ttotal: 18.6s\tremaining: 1m 32s\n",
      "96:\tlearn: 0.0185433\ttotal: 18.8s\tremaining: 1m 32s\n",
      "97:\tlearn: 0.0185406\ttotal: 19s\tremaining: 1m 32s\n",
      "98:\tlearn: 0.0185391\ttotal: 19.2s\tremaining: 1m 32s\n",
      "99:\tlearn: 0.0185383\ttotal: 19.4s\tremaining: 1m 32s\n",
      "100:\tlearn: 0.0185376\ttotal: 19.6s\tremaining: 1m 32s\n",
      "101:\tlearn: 0.0185370\ttotal: 19.8s\tremaining: 1m 31s\n",
      "102:\tlearn: 0.0185355\ttotal: 20s\tremaining: 1m 31s\n",
      "103:\tlearn: 0.0185343\ttotal: 20.2s\tremaining: 1m 31s\n",
      "104:\tlearn: 0.0185328\ttotal: 20.3s\tremaining: 1m 31s\n",
      "105:\tlearn: 0.0185320\ttotal: 20.5s\tremaining: 1m 30s\n",
      "106:\tlearn: 0.0185310\ttotal: 20.6s\tremaining: 1m 30s\n",
      "107:\tlearn: 0.0185305\ttotal: 20.7s\tremaining: 1m 29s\n",
      "108:\tlearn: 0.0185290\ttotal: 21s\tremaining: 1m 29s\n",
      "109:\tlearn: 0.0185277\ttotal: 21.2s\tremaining: 1m 29s\n",
      "110:\tlearn: 0.0185272\ttotal: 21.3s\tremaining: 1m 29s\n",
      "111:\tlearn: 0.0185258\ttotal: 21.5s\tremaining: 1m 28s\n",
      "112:\tlearn: 0.0185249\ttotal: 21.7s\tremaining: 1m 28s\n",
      "113:\tlearn: 0.0185237\ttotal: 21.9s\tremaining: 1m 28s\n",
      "114:\tlearn: 0.0185231\ttotal: 22s\tremaining: 1m 28s\n",
      "115:\tlearn: 0.0185224\ttotal: 22.2s\tremaining: 1m 27s\n",
      "116:\tlearn: 0.0185218\ttotal: 22.4s\tremaining: 1m 27s\n",
      "117:\tlearn: 0.0185211\ttotal: 22.7s\tremaining: 1m 27s\n",
      "118:\tlearn: 0.0185200\ttotal: 23s\tremaining: 1m 28s\n",
      "119:\tlearn: 0.0185186\ttotal: 23.2s\tremaining: 1m 28s\n",
      "120:\tlearn: 0.0185178\ttotal: 23.4s\tremaining: 1m 27s\n",
      "121:\tlearn: 0.0185171\ttotal: 23.7s\tremaining: 1m 27s\n",
      "122:\tlearn: 0.0185160\ttotal: 23.9s\tremaining: 1m 27s\n",
      "123:\tlearn: 0.0185151\ttotal: 24.3s\tremaining: 1m 28s\n",
      "124:\tlearn: 0.0185134\ttotal: 24.6s\tremaining: 1m 28s\n",
      "125:\tlearn: 0.0185124\ttotal: 24.8s\tremaining: 1m 28s\n",
      "126:\tlearn: 0.0185113\ttotal: 25s\tremaining: 1m 28s\n",
      "127:\tlearn: 0.0185105\ttotal: 25.2s\tremaining: 1m 27s\n",
      "128:\tlearn: 0.0185094\ttotal: 25.4s\tremaining: 1m 27s\n",
      "129:\tlearn: 0.0185084\ttotal: 25.6s\tremaining: 1m 27s\n",
      "130:\tlearn: 0.0185076\ttotal: 25.7s\tremaining: 1m 27s\n",
      "131:\tlearn: 0.0185067\ttotal: 26s\tremaining: 1m 27s\n",
      "132:\tlearn: 0.0185062\ttotal: 26.1s\tremaining: 1m 26s\n",
      "133:\tlearn: 0.0185052\ttotal: 26.3s\tremaining: 1m 26s\n",
      "134:\tlearn: 0.0185050\ttotal: 26.5s\tremaining: 1m 26s\n",
      "135:\tlearn: 0.0185040\ttotal: 26.9s\tremaining: 1m 26s\n",
      "136:\tlearn: 0.0185034\ttotal: 27.2s\tremaining: 1m 26s\n",
      "137:\tlearn: 0.0185028\ttotal: 27.3s\tremaining: 1m 26s\n",
      "138:\tlearn: 0.0185017\ttotal: 27.5s\tremaining: 1m 26s\n",
      "139:\tlearn: 0.0185006\ttotal: 27.7s\tremaining: 1m 25s\n",
      "140:\tlearn: 0.0185002\ttotal: 27.8s\tremaining: 1m 25s\n",
      "141:\tlearn: 0.0184994\ttotal: 28s\tremaining: 1m 25s\n",
      "142:\tlearn: 0.0184982\ttotal: 28.1s\tremaining: 1m 25s\n",
      "143:\tlearn: 0.0184978\ttotal: 28.3s\tremaining: 1m 24s\n",
      "144:\tlearn: 0.0184973\ttotal: 28.5s\tremaining: 1m 24s\n",
      "145:\tlearn: 0.0184967\ttotal: 28.6s\tremaining: 1m 24s\n",
      "146:\tlearn: 0.0184963\ttotal: 28.8s\tremaining: 1m 23s\n",
      "147:\tlearn: 0.0184960\ttotal: 28.9s\tremaining: 1m 23s\n",
      "148:\tlearn: 0.0184952\ttotal: 29.1s\tremaining: 1m 23s\n",
      "149:\tlearn: 0.0184950\ttotal: 29.2s\tremaining: 1m 22s\n",
      "150:\tlearn: 0.0184942\ttotal: 29.4s\tremaining: 1m 22s\n",
      "151:\tlearn: 0.0184934\ttotal: 29.6s\tremaining: 1m 22s\n",
      "152:\tlearn: 0.0184927\ttotal: 29.7s\tremaining: 1m 21s\n",
      "153:\tlearn: 0.0184923\ttotal: 29.9s\tremaining: 1m 21s\n",
      "154:\tlearn: 0.0184919\ttotal: 30.1s\tremaining: 1m 21s\n",
      "155:\tlearn: 0.0184912\ttotal: 30.3s\tremaining: 1m 21s\n",
      "156:\tlearn: 0.0184908\ttotal: 30.4s\tremaining: 1m 20s\n",
      "157:\tlearn: 0.0184901\ttotal: 30.6s\tremaining: 1m 20s\n",
      "158:\tlearn: 0.0184889\ttotal: 30.7s\tremaining: 1m 20s\n",
      "159:\tlearn: 0.0184880\ttotal: 30.9s\tremaining: 1m 20s\n",
      "160:\tlearn: 0.0184870\ttotal: 31.1s\tremaining: 1m 19s\n",
      "161:\tlearn: 0.0184863\ttotal: 31.2s\tremaining: 1m 19s\n",
      "162:\tlearn: 0.0184856\ttotal: 31.4s\tremaining: 1m 19s\n",
      "163:\tlearn: 0.0184851\ttotal: 31.5s\tremaining: 1m 19s\n",
      "164:\tlearn: 0.0184843\ttotal: 31.7s\tremaining: 1m 18s\n",
      "165:\tlearn: 0.0184838\ttotal: 31.9s\tremaining: 1m 18s\n",
      "166:\tlearn: 0.0184834\ttotal: 32.1s\tremaining: 1m 18s\n",
      "167:\tlearn: 0.0184827\ttotal: 32.3s\tremaining: 1m 18s\n",
      "168:\tlearn: 0.0184819\ttotal: 32.5s\tremaining: 1m 18s\n",
      "169:\tlearn: 0.0184810\ttotal: 32.7s\tremaining: 1m 17s\n",
      "170:\tlearn: 0.0184806\ttotal: 32.8s\tremaining: 1m 17s\n",
      "171:\tlearn: 0.0184802\ttotal: 33s\tremaining: 1m 17s\n",
      "172:\tlearn: 0.0184796\ttotal: 33.1s\tremaining: 1m 16s\n",
      "173:\tlearn: 0.0184792\ttotal: 33.3s\tremaining: 1m 16s\n",
      "174:\tlearn: 0.0184787\ttotal: 33.4s\tremaining: 1m 16s\n",
      "175:\tlearn: 0.0184782\ttotal: 33.6s\tremaining: 1m 16s\n",
      "176:\tlearn: 0.0184774\ttotal: 33.7s\tremaining: 1m 15s\n",
      "177:\tlearn: 0.0184767\ttotal: 33.9s\tremaining: 1m 15s\n",
      "178:\tlearn: 0.0184762\ttotal: 34s\tremaining: 1m 15s\n",
      "179:\tlearn: 0.0184757\ttotal: 34.2s\tremaining: 1m 14s\n",
      "180:\tlearn: 0.0184752\ttotal: 34.3s\tremaining: 1m 14s\n",
      "181:\tlearn: 0.0184747\ttotal: 34.5s\tremaining: 1m 14s\n",
      "182:\tlearn: 0.0184742\ttotal: 34.7s\tremaining: 1m 14s\n",
      "183:\tlearn: 0.0184739\ttotal: 34.8s\tremaining: 1m 14s\n",
      "184:\tlearn: 0.0184732\ttotal: 35s\tremaining: 1m 13s\n",
      "185:\tlearn: 0.0184728\ttotal: 35.1s\tremaining: 1m 13s\n",
      "186:\tlearn: 0.0184724\ttotal: 35.3s\tremaining: 1m 13s\n",
      "187:\tlearn: 0.0184718\ttotal: 35.4s\tremaining: 1m 12s\n",
      "188:\tlearn: 0.0184714\ttotal: 35.6s\tremaining: 1m 12s\n",
      "189:\tlearn: 0.0184707\ttotal: 35.8s\tremaining: 1m 12s\n",
      "190:\tlearn: 0.0184700\ttotal: 36s\tremaining: 1m 12s\n",
      "191:\tlearn: 0.0184696\ttotal: 36.2s\tremaining: 1m 12s\n",
      "192:\tlearn: 0.0184691\ttotal: 36.3s\tremaining: 1m 11s\n",
      "193:\tlearn: 0.0184688\ttotal: 36.5s\tremaining: 1m 11s\n",
      "194:\tlearn: 0.0184684\ttotal: 36.6s\tremaining: 1m 11s\n",
      "195:\tlearn: 0.0184681\ttotal: 36.8s\tremaining: 1m 11s\n",
      "196:\tlearn: 0.0184678\ttotal: 36.9s\tremaining: 1m 10s\n",
      "197:\tlearn: 0.0184671\ttotal: 37.2s\tremaining: 1m 10s\n",
      "198:\tlearn: 0.0184668\ttotal: 37.4s\tremaining: 1m 10s\n",
      "199:\tlearn: 0.0184663\ttotal: 37.6s\tremaining: 1m 10s\n",
      "200:\tlearn: 0.0184658\ttotal: 37.8s\tremaining: 1m 10s\n",
      "201:\tlearn: 0.0184652\ttotal: 37.9s\tremaining: 1m 10s\n",
      "202:\tlearn: 0.0184647\ttotal: 38.1s\tremaining: 1m 9s\n",
      "203:\tlearn: 0.0184640\ttotal: 38.2s\tremaining: 1m 9s\n",
      "204:\tlearn: 0.0184636\ttotal: 38.4s\tremaining: 1m 9s\n",
      "205:\tlearn: 0.0184631\ttotal: 38.6s\tremaining: 1m 9s\n",
      "206:\tlearn: 0.0184629\ttotal: 38.7s\tremaining: 1m 8s\n",
      "207:\tlearn: 0.0184625\ttotal: 38.8s\tremaining: 1m 8s\n",
      "208:\tlearn: 0.0184623\ttotal: 39s\tremaining: 1m 8s\n",
      "209:\tlearn: 0.0184619\ttotal: 39.1s\tremaining: 1m 8s\n",
      "210:\tlearn: 0.0184612\ttotal: 39.3s\tremaining: 1m 7s\n",
      "211:\tlearn: 0.0184608\ttotal: 39.5s\tremaining: 1m 7s\n",
      "212:\tlearn: 0.0184604\ttotal: 39.6s\tremaining: 1m 7s\n",
      "213:\tlearn: 0.0184598\ttotal: 39.8s\tremaining: 1m 7s\n",
      "214:\tlearn: 0.0184593\ttotal: 40s\tremaining: 1m 6s\n",
      "215:\tlearn: 0.0184588\ttotal: 40.1s\tremaining: 1m 6s\n",
      "216:\tlearn: 0.0184583\ttotal: 40.3s\tremaining: 1m 6s\n",
      "217:\tlearn: 0.0184579\ttotal: 40.4s\tremaining: 1m 6s\n",
      "218:\tlearn: 0.0184575\ttotal: 40.6s\tremaining: 1m 5s\n",
      "219:\tlearn: 0.0184573\ttotal: 40.7s\tremaining: 1m 5s\n",
      "220:\tlearn: 0.0184568\ttotal: 40.9s\tremaining: 1m 5s\n",
      "221:\tlearn: 0.0184565\ttotal: 41s\tremaining: 1m 5s\n",
      "222:\tlearn: 0.0184561\ttotal: 41.2s\tremaining: 1m 5s\n",
      "223:\tlearn: 0.0184557\ttotal: 41.4s\tremaining: 1m 4s\n",
      "224:\tlearn: 0.0184553\ttotal: 41.5s\tremaining: 1m 4s\n",
      "225:\tlearn: 0.0184548\ttotal: 41.7s\tremaining: 1m 4s\n",
      "226:\tlearn: 0.0184544\ttotal: 41.9s\tremaining: 1m 4s\n",
      "227:\tlearn: 0.0184541\ttotal: 42.1s\tremaining: 1m 4s\n",
      "228:\tlearn: 0.0184538\ttotal: 42.3s\tremaining: 1m 3s\n",
      "229:\tlearn: 0.0184534\ttotal: 42.5s\tremaining: 1m 3s\n",
      "230:\tlearn: 0.0184529\ttotal: 42.8s\tremaining: 1m 3s\n",
      "231:\tlearn: 0.0184528\ttotal: 43s\tremaining: 1m 3s\n",
      "232:\tlearn: 0.0184525\ttotal: 43.2s\tremaining: 1m 3s\n",
      "233:\tlearn: 0.0184523\ttotal: 43.3s\tremaining: 1m 3s\n",
      "234:\tlearn: 0.0184521\ttotal: 43.5s\tremaining: 1m 2s\n",
      "235:\tlearn: 0.0184516\ttotal: 43.6s\tremaining: 1m 2s\n",
      "236:\tlearn: 0.0184512\ttotal: 43.8s\tremaining: 1m 2s\n",
      "237:\tlearn: 0.0184508\ttotal: 43.9s\tremaining: 1m 2s\n",
      "238:\tlearn: 0.0184504\ttotal: 44.1s\tremaining: 1m 1s\n",
      "239:\tlearn: 0.0184502\ttotal: 44.2s\tremaining: 1m 1s\n",
      "240:\tlearn: 0.0184497\ttotal: 44.4s\tremaining: 1m 1s\n",
      "241:\tlearn: 0.0184490\ttotal: 44.5s\tremaining: 1m 1s\n",
      "242:\tlearn: 0.0184487\ttotal: 44.7s\tremaining: 1m 1s\n",
      "243:\tlearn: 0.0184484\ttotal: 44.8s\tremaining: 1m\n",
      "244:\tlearn: 0.0184482\ttotal: 45s\tremaining: 1m\n",
      "245:\tlearn: 0.0184479\ttotal: 45.1s\tremaining: 1m\n",
      "246:\tlearn: 0.0184476\ttotal: 45.2s\tremaining: 1m\n",
      "247:\tlearn: 0.0184474\ttotal: 45.4s\tremaining: 59.9s\n",
      "248:\tlearn: 0.0184471\ttotal: 45.5s\tremaining: 59.6s\n",
      "249:\tlearn: 0.0184467\ttotal: 45.7s\tremaining: 59.4s\n",
      "250:\tlearn: 0.0184465\ttotal: 45.8s\tremaining: 59.1s\n",
      "251:\tlearn: 0.0184461\ttotal: 46s\tremaining: 58.9s\n",
      "252:\tlearn: 0.0184457\ttotal: 46.1s\tremaining: 58.7s\n",
      "253:\tlearn: 0.0184455\ttotal: 46.2s\tremaining: 58.4s\n",
      "254:\tlearn: 0.0184453\ttotal: 46.3s\tremaining: 58.1s\n",
      "255:\tlearn: 0.0184450\ttotal: 46.4s\tremaining: 57.9s\n",
      "256:\tlearn: 0.0184446\ttotal: 46.6s\tremaining: 57.6s\n",
      "257:\tlearn: 0.0184445\ttotal: 46.7s\tremaining: 57.4s\n",
      "258:\tlearn: 0.0184442\ttotal: 46.8s\tremaining: 57.1s\n",
      "259:\tlearn: 0.0184439\ttotal: 46.9s\tremaining: 56.9s\n",
      "260:\tlearn: 0.0184433\ttotal: 47.1s\tremaining: 56.7s\n",
      "261:\tlearn: 0.0184430\ttotal: 47.2s\tremaining: 56.4s\n",
      "262:\tlearn: 0.0184426\ttotal: 47.4s\tremaining: 56.2s\n",
      "263:\tlearn: 0.0184419\ttotal: 47.6s\tremaining: 56.1s\n",
      "264:\tlearn: 0.0184415\ttotal: 47.7s\tremaining: 55.8s\n",
      "265:\tlearn: 0.0184409\ttotal: 47.9s\tremaining: 55.6s\n",
      "266:\tlearn: 0.0184404\ttotal: 48.1s\tremaining: 55.5s\n",
      "267:\tlearn: 0.0184402\ttotal: 48.2s\tremaining: 55.2s\n",
      "268:\tlearn: 0.0184399\ttotal: 48.4s\tremaining: 55.1s\n",
      "269:\tlearn: 0.0184397\ttotal: 48.6s\tremaining: 54.9s\n",
      "270:\tlearn: 0.0184395\ttotal: 48.7s\tremaining: 54.6s\n",
      "271:\tlearn: 0.0184393\ttotal: 48.9s\tremaining: 54.4s\n",
      "272:\tlearn: 0.0184390\ttotal: 49s\tremaining: 54.2s\n",
      "273:\tlearn: 0.0184387\ttotal: 49.2s\tremaining: 54s\n",
      "274:\tlearn: 0.0184385\ttotal: 49.3s\tremaining: 53.8s\n",
      "275:\tlearn: 0.0184383\ttotal: 49.5s\tremaining: 53.6s\n",
      "276:\tlearn: 0.0184381\ttotal: 49.6s\tremaining: 53.4s\n",
      "277:\tlearn: 0.0184377\ttotal: 49.8s\tremaining: 53.2s\n",
      "278:\tlearn: 0.0184375\ttotal: 49.9s\tremaining: 52.9s\n",
      "279:\tlearn: 0.0184374\ttotal: 50s\tremaining: 52.7s\n",
      "280:\tlearn: 0.0184369\ttotal: 50.2s\tremaining: 52.5s\n",
      "281:\tlearn: 0.0184367\ttotal: 50.3s\tremaining: 52.3s\n",
      "282:\tlearn: 0.0184365\ttotal: 50.4s\tremaining: 52s\n",
      "283:\tlearn: 0.0184363\ttotal: 50.5s\tremaining: 51.8s\n",
      "284:\tlearn: 0.0184360\ttotal: 50.7s\tremaining: 51.6s\n",
      "285:\tlearn: 0.0184356\ttotal: 50.8s\tremaining: 51.3s\n",
      "286:\tlearn: 0.0184354\ttotal: 50.9s\tremaining: 51.1s\n",
      "287:\tlearn: 0.0184352\ttotal: 51s\tremaining: 50.8s\n",
      "288:\tlearn: 0.0184348\ttotal: 51.2s\tremaining: 50.7s\n",
      "289:\tlearn: 0.0184347\ttotal: 51.4s\tremaining: 50.5s\n",
      "290:\tlearn: 0.0184343\ttotal: 51.5s\tremaining: 50.3s\n",
      "291:\tlearn: 0.0184342\ttotal: 51.7s\tremaining: 50.1s\n",
      "292:\tlearn: 0.0184338\ttotal: 51.8s\tremaining: 49.9s\n",
      "293:\tlearn: 0.0184337\ttotal: 51.9s\tremaining: 49.7s\n",
      "294:\tlearn: 0.0184333\ttotal: 52.1s\tremaining: 49.5s\n",
      "295:\tlearn: 0.0184331\ttotal: 52.2s\tremaining: 49.2s\n",
      "296:\tlearn: 0.0184329\ttotal: 52.4s\tremaining: 49s\n",
      "297:\tlearn: 0.0184326\ttotal: 52.5s\tremaining: 48.8s\n",
      "298:\tlearn: 0.0184325\ttotal: 52.7s\tremaining: 48.6s\n",
      "299:\tlearn: 0.0184322\ttotal: 52.8s\tremaining: 48.4s\n",
      "300:\tlearn: 0.0184318\ttotal: 53s\tremaining: 48.2s\n",
      "301:\tlearn: 0.0184317\ttotal: 53.1s\tremaining: 48s\n",
      "302:\tlearn: 0.0184314\ttotal: 53.3s\tremaining: 47.8s\n",
      "303:\tlearn: 0.0184313\ttotal: 53.4s\tremaining: 47.6s\n",
      "304:\tlearn: 0.0184311\ttotal: 53.5s\tremaining: 47.4s\n",
      "305:\tlearn: 0.0184305\ttotal: 53.7s\tremaining: 47.2s\n",
      "306:\tlearn: 0.0184304\ttotal: 53.8s\tremaining: 47s\n",
      "307:\tlearn: 0.0184301\ttotal: 54s\tremaining: 46.8s\n",
      "308:\tlearn: 0.0184298\ttotal: 54.1s\tremaining: 46.6s\n",
      "309:\tlearn: 0.0184295\ttotal: 54.3s\tremaining: 46.4s\n",
      "310:\tlearn: 0.0184291\ttotal: 54.4s\tremaining: 46.2s\n",
      "311:\tlearn: 0.0184287\ttotal: 54.6s\tremaining: 46s\n",
      "312:\tlearn: 0.0184283\ttotal: 54.8s\tremaining: 45.8s\n",
      "313:\tlearn: 0.0184280\ttotal: 54.9s\tremaining: 45.6s\n",
      "314:\tlearn: 0.0184278\ttotal: 55.1s\tremaining: 45.5s\n",
      "315:\tlearn: 0.0184273\ttotal: 55.2s\tremaining: 45.3s\n",
      "316:\tlearn: 0.0184272\ttotal: 55.4s\tremaining: 45.1s\n",
      "317:\tlearn: 0.0184271\ttotal: 55.6s\tremaining: 44.9s\n",
      "318:\tlearn: 0.0184269\ttotal: 55.7s\tremaining: 44.7s\n",
      "319:\tlearn: 0.0184266\ttotal: 55.9s\tremaining: 44.5s\n",
      "320:\tlearn: 0.0184264\ttotal: 56s\tremaining: 44.3s\n",
      "321:\tlearn: 0.0184260\ttotal: 56.2s\tremaining: 44.2s\n",
      "322:\tlearn: 0.0184259\ttotal: 56.3s\tremaining: 44s\n",
      "323:\tlearn: 0.0184256\ttotal: 56.5s\tremaining: 43.8s\n",
      "324:\tlearn: 0.0184254\ttotal: 56.6s\tremaining: 43.6s\n",
      "325:\tlearn: 0.0184251\ttotal: 56.8s\tremaining: 43.4s\n",
      "326:\tlearn: 0.0184250\ttotal: 56.9s\tremaining: 43.2s\n",
      "327:\tlearn: 0.0184246\ttotal: 57.1s\tremaining: 43s\n",
      "328:\tlearn: 0.0184244\ttotal: 57.2s\tremaining: 42.8s\n",
      "329:\tlearn: 0.0184243\ttotal: 57.4s\tremaining: 42.6s\n",
      "330:\tlearn: 0.0184240\ttotal: 57.6s\tremaining: 42.4s\n",
      "331:\tlearn: 0.0184236\ttotal: 57.7s\tremaining: 42.2s\n",
      "332:\tlearn: 0.0184232\ttotal: 57.9s\tremaining: 42.1s\n",
      "333:\tlearn: 0.0184231\ttotal: 58.2s\tremaining: 42s\n",
      "334:\tlearn: 0.0184229\ttotal: 58.3s\tremaining: 41.8s\n",
      "335:\tlearn: 0.0184227\ttotal: 58.5s\tremaining: 41.6s\n",
      "336:\tlearn: 0.0184224\ttotal: 58.6s\tremaining: 41.4s\n",
      "337:\tlearn: 0.0184222\ttotal: 58.8s\tremaining: 41.2s\n",
      "338:\tlearn: 0.0184221\ttotal: 58.9s\tremaining: 41s\n",
      "339:\tlearn: 0.0184218\ttotal: 59.1s\tremaining: 40.9s\n",
      "340:\tlearn: 0.0184216\ttotal: 59.3s\tremaining: 40.7s\n",
      "341:\tlearn: 0.0184213\ttotal: 59.4s\tremaining: 40.5s\n",
      "342:\tlearn: 0.0184211\ttotal: 59.5s\tremaining: 40.3s\n",
      "343:\tlearn: 0.0184210\ttotal: 59.7s\tremaining: 40.1s\n",
      "344:\tlearn: 0.0184208\ttotal: 59.9s\tremaining: 39.9s\n",
      "345:\tlearn: 0.0184207\ttotal: 1m\tremaining: 39.7s\n",
      "346:\tlearn: 0.0184203\ttotal: 1m\tremaining: 39.5s\n",
      "347:\tlearn: 0.0184200\ttotal: 1m\tremaining: 39.4s\n",
      "348:\tlearn: 0.0184197\ttotal: 1m\tremaining: 39.2s\n",
      "349:\tlearn: 0.0184195\ttotal: 1m\tremaining: 39s\n",
      "350:\tlearn: 0.0184192\ttotal: 1m\tremaining: 38.8s\n",
      "351:\tlearn: 0.0184189\ttotal: 1m 1s\tremaining: 38.6s\n",
      "352:\tlearn: 0.0184187\ttotal: 1m 1s\tremaining: 38.5s\n",
      "353:\tlearn: 0.0184185\ttotal: 1m 1s\tremaining: 38.3s\n",
      "354:\tlearn: 0.0184184\ttotal: 1m 1s\tremaining: 38.1s\n",
      "355:\tlearn: 0.0184179\ttotal: 1m 1s\tremaining: 37.9s\n",
      "356:\tlearn: 0.0184178\ttotal: 1m 1s\tremaining: 37.7s\n",
      "357:\tlearn: 0.0184175\ttotal: 1m 1s\tremaining: 37.5s\n",
      "358:\tlearn: 0.0184172\ttotal: 1m 2s\tremaining: 37.3s\n",
      "359:\tlearn: 0.0184171\ttotal: 1m 2s\tremaining: 37.1s\n",
      "360:\tlearn: 0.0184170\ttotal: 1m 2s\tremaining: 36.9s\n",
      "361:\tlearn: 0.0184166\ttotal: 1m 2s\tremaining: 36.7s\n",
      "362:\tlearn: 0.0184162\ttotal: 1m 2s\tremaining: 36.5s\n",
      "363:\tlearn: 0.0184160\ttotal: 1m 2s\tremaining: 36.3s\n",
      "364:\tlearn: 0.0184158\ttotal: 1m 2s\tremaining: 36.1s\n",
      "365:\tlearn: 0.0184156\ttotal: 1m 2s\tremaining: 36s\n",
      "366:\tlearn: 0.0184154\ttotal: 1m 3s\tremaining: 35.8s\n",
      "367:\tlearn: 0.0184151\ttotal: 1m 3s\tremaining: 35.6s\n",
      "368:\tlearn: 0.0184150\ttotal: 1m 3s\tremaining: 35.4s\n",
      "369:\tlearn: 0.0184149\ttotal: 1m 3s\tremaining: 35.2s\n",
      "370:\tlearn: 0.0184148\ttotal: 1m 3s\tremaining: 35s\n",
      "371:\tlearn: 0.0184146\ttotal: 1m 3s\tremaining: 34.8s\n",
      "372:\tlearn: 0.0184145\ttotal: 1m 3s\tremaining: 34.6s\n",
      "373:\tlearn: 0.0184142\ttotal: 1m 3s\tremaining: 34.4s\n",
      "374:\tlearn: 0.0184141\ttotal: 1m 4s\tremaining: 34.2s\n",
      "375:\tlearn: 0.0184140\ttotal: 1m 4s\tremaining: 34s\n",
      "376:\tlearn: 0.0184139\ttotal: 1m 4s\tremaining: 33.8s\n",
      "377:\tlearn: 0.0184138\ttotal: 1m 4s\tremaining: 33.6s\n",
      "378:\tlearn: 0.0184136\ttotal: 1m 4s\tremaining: 33.4s\n",
      "379:\tlearn: 0.0184134\ttotal: 1m 4s\tremaining: 33.2s\n",
      "380:\tlearn: 0.0184132\ttotal: 1m 4s\tremaining: 33s\n",
      "381:\tlearn: 0.0184131\ttotal: 1m 5s\tremaining: 32.8s\n",
      "382:\tlearn: 0.0184128\ttotal: 1m 5s\tremaining: 32.7s\n",
      "383:\tlearn: 0.0184126\ttotal: 1m 5s\tremaining: 32.5s\n",
      "384:\tlearn: 0.0184125\ttotal: 1m 5s\tremaining: 32.3s\n",
      "385:\tlearn: 0.0184123\ttotal: 1m 5s\tremaining: 32.1s\n",
      "386:\tlearn: 0.0184122\ttotal: 1m 5s\tremaining: 31.9s\n",
      "387:\tlearn: 0.0184121\ttotal: 1m 5s\tremaining: 31.7s\n",
      "388:\tlearn: 0.0184117\ttotal: 1m 5s\tremaining: 31.6s\n",
      "389:\tlearn: 0.0184116\ttotal: 1m 6s\tremaining: 31.4s\n",
      "390:\tlearn: 0.0184114\ttotal: 1m 6s\tremaining: 31.2s\n",
      "391:\tlearn: 0.0184112\ttotal: 1m 6s\tremaining: 31s\n",
      "392:\tlearn: 0.0184108\ttotal: 1m 6s\tremaining: 30.8s\n",
      "393:\tlearn: 0.0184104\ttotal: 1m 6s\tremaining: 30.6s\n",
      "394:\tlearn: 0.0184102\ttotal: 1m 6s\tremaining: 30.4s\n",
      "395:\tlearn: 0.0184100\ttotal: 1m 6s\tremaining: 30.2s\n",
      "396:\tlearn: 0.0184098\ttotal: 1m 7s\tremaining: 30.1s\n",
      "397:\tlearn: 0.0184095\ttotal: 1m 7s\tremaining: 29.9s\n",
      "398:\tlearn: 0.0184092\ttotal: 1m 7s\tremaining: 29.8s\n",
      "399:\tlearn: 0.0184087\ttotal: 1m 7s\tremaining: 29.6s\n",
      "400:\tlearn: 0.0184085\ttotal: 1m 7s\tremaining: 29.4s\n",
      "401:\tlearn: 0.0184083\ttotal: 1m 7s\tremaining: 29.2s\n",
      "402:\tlearn: 0.0184079\ttotal: 1m 8s\tremaining: 29.1s\n",
      "403:\tlearn: 0.0184076\ttotal: 1m 8s\tremaining: 28.9s\n",
      "404:\tlearn: 0.0184076\ttotal: 1m 8s\tremaining: 28.7s\n",
      "405:\tlearn: 0.0184074\ttotal: 1m 8s\tremaining: 28.5s\n",
      "406:\tlearn: 0.0184073\ttotal: 1m 8s\tremaining: 28.3s\n",
      "407:\tlearn: 0.0184070\ttotal: 1m 8s\tremaining: 28.1s\n",
      "408:\tlearn: 0.0184068\ttotal: 1m 8s\tremaining: 27.9s\n",
      "409:\tlearn: 0.0184067\ttotal: 1m 8s\tremaining: 27.8s\n",
      "410:\tlearn: 0.0184065\ttotal: 1m 9s\tremaining: 27.6s\n",
      "411:\tlearn: 0.0184063\ttotal: 1m 9s\tremaining: 27.4s\n",
      "412:\tlearn: 0.0184061\ttotal: 1m 9s\tremaining: 27.2s\n",
      "413:\tlearn: 0.0184057\ttotal: 1m 9s\tremaining: 27.1s\n",
      "414:\tlearn: 0.0184056\ttotal: 1m 9s\tremaining: 26.9s\n",
      "415:\tlearn: 0.0184054\ttotal: 1m 9s\tremaining: 26.7s\n",
      "416:\tlearn: 0.0184050\ttotal: 1m 9s\tremaining: 26.5s\n",
      "417:\tlearn: 0.0184049\ttotal: 1m 10s\tremaining: 26.3s\n",
      "418:\tlearn: 0.0184046\ttotal: 1m 10s\tremaining: 26.1s\n",
      "419:\tlearn: 0.0184044\ttotal: 1m 10s\tremaining: 25.9s\n",
      "420:\tlearn: 0.0184043\ttotal: 1m 10s\tremaining: 25.8s\n",
      "421:\tlearn: 0.0184041\ttotal: 1m 10s\tremaining: 25.6s\n",
      "422:\tlearn: 0.0184038\ttotal: 1m 10s\tremaining: 25.4s\n",
      "423:\tlearn: 0.0184037\ttotal: 1m 10s\tremaining: 25.2s\n",
      "424:\tlearn: 0.0184034\ttotal: 1m 10s\tremaining: 25.1s\n",
      "425:\tlearn: 0.0184032\ttotal: 1m 11s\tremaining: 24.9s\n",
      "426:\tlearn: 0.0184030\ttotal: 1m 11s\tremaining: 24.8s\n",
      "427:\tlearn: 0.0184027\ttotal: 1m 11s\tremaining: 24.6s\n",
      "428:\tlearn: 0.0184027\ttotal: 1m 11s\tremaining: 24.4s\n",
      "429:\tlearn: 0.0184026\ttotal: 1m 11s\tremaining: 24.2s\n",
      "430:\tlearn: 0.0184024\ttotal: 1m 11s\tremaining: 24s\n",
      "431:\tlearn: 0.0184023\ttotal: 1m 12s\tremaining: 23.9s\n",
      "432:\tlearn: 0.0184021\ttotal: 1m 12s\tremaining: 23.7s\n",
      "433:\tlearn: 0.0184017\ttotal: 1m 12s\tremaining: 23.5s\n",
      "434:\tlearn: 0.0184017\ttotal: 1m 12s\tremaining: 23.3s\n",
      "435:\tlearn: 0.0184015\ttotal: 1m 12s\tremaining: 23.1s\n",
      "436:\tlearn: 0.0184014\ttotal: 1m 12s\tremaining: 22.9s\n",
      "437:\tlearn: 0.0184012\ttotal: 1m 12s\tremaining: 22.8s\n",
      "438:\tlearn: 0.0184011\ttotal: 1m 12s\tremaining: 22.6s\n",
      "439:\tlearn: 0.0184010\ttotal: 1m 12s\tremaining: 22.4s\n",
      "440:\tlearn: 0.0184009\ttotal: 1m 13s\tremaining: 22.2s\n",
      "441:\tlearn: 0.0184007\ttotal: 1m 13s\tremaining: 22s\n",
      "442:\tlearn: 0.0184005\ttotal: 1m 13s\tremaining: 21.9s\n",
      "443:\tlearn: 0.0184004\ttotal: 1m 13s\tremaining: 21.7s\n",
      "444:\tlearn: 0.0184001\ttotal: 1m 13s\tremaining: 21.5s\n",
      "445:\tlearn: 0.0183998\ttotal: 1m 13s\tremaining: 21.3s\n",
      "446:\tlearn: 0.0183997\ttotal: 1m 13s\tremaining: 21.1s\n",
      "447:\tlearn: 0.0183994\ttotal: 1m 13s\tremaining: 21s\n",
      "448:\tlearn: 0.0183993\ttotal: 1m 14s\tremaining: 20.8s\n",
      "449:\tlearn: 0.0183990\ttotal: 1m 14s\tremaining: 20.6s\n",
      "450:\tlearn: 0.0183988\ttotal: 1m 14s\tremaining: 20.4s\n",
      "451:\tlearn: 0.0183987\ttotal: 1m 14s\tremaining: 20.3s\n",
      "452:\tlearn: 0.0183984\ttotal: 1m 14s\tremaining: 20.1s\n",
      "453:\tlearn: 0.0183982\ttotal: 1m 14s\tremaining: 19.9s\n",
      "454:\tlearn: 0.0183980\ttotal: 1m 14s\tremaining: 19.7s\n",
      "455:\tlearn: 0.0183978\ttotal: 1m 14s\tremaining: 19.6s\n",
      "456:\tlearn: 0.0183977\ttotal: 1m 15s\tremaining: 19.4s\n",
      "457:\tlearn: 0.0183974\ttotal: 1m 15s\tremaining: 19.2s\n",
      "458:\tlearn: 0.0183972\ttotal: 1m 15s\tremaining: 19s\n",
      "459:\tlearn: 0.0183970\ttotal: 1m 15s\tremaining: 18.9s\n",
      "460:\tlearn: 0.0183969\ttotal: 1m 15s\tremaining: 18.7s\n",
      "461:\tlearn: 0.0183967\ttotal: 1m 15s\tremaining: 18.5s\n",
      "462:\tlearn: 0.0183966\ttotal: 1m 15s\tremaining: 18.3s\n",
      "463:\tlearn: 0.0183962\ttotal: 1m 15s\tremaining: 18.2s\n",
      "464:\tlearn: 0.0183960\ttotal: 1m 16s\tremaining: 18s\n",
      "465:\tlearn: 0.0183958\ttotal: 1m 16s\tremaining: 17.8s\n",
      "466:\tlearn: 0.0183957\ttotal: 1m 16s\tremaining: 17.6s\n",
      "467:\tlearn: 0.0183954\ttotal: 1m 16s\tremaining: 17.5s\n",
      "468:\tlearn: 0.0183952\ttotal: 1m 16s\tremaining: 17.3s\n",
      "469:\tlearn: 0.0183949\ttotal: 1m 16s\tremaining: 17.1s\n",
      "470:\tlearn: 0.0183947\ttotal: 1m 16s\tremaining: 17s\n",
      "471:\tlearn: 0.0183945\ttotal: 1m 16s\tremaining: 16.8s\n",
      "472:\tlearn: 0.0183944\ttotal: 1m 17s\tremaining: 16.6s\n",
      "473:\tlearn: 0.0183944\ttotal: 1m 17s\tremaining: 16.4s\n",
      "474:\tlearn: 0.0183940\ttotal: 1m 17s\tremaining: 16.3s\n",
      "475:\tlearn: 0.0183938\ttotal: 1m 17s\tremaining: 16.1s\n",
      "476:\tlearn: 0.0183936\ttotal: 1m 17s\tremaining: 15.9s\n",
      "477:\tlearn: 0.0183934\ttotal: 1m 17s\tremaining: 15.7s\n",
      "478:\tlearn: 0.0183932\ttotal: 1m 17s\tremaining: 15.6s\n",
      "479:\tlearn: 0.0183930\ttotal: 1m 17s\tremaining: 15.4s\n",
      "480:\tlearn: 0.0183928\ttotal: 1m 17s\tremaining: 15.2s\n",
      "481:\tlearn: 0.0183925\ttotal: 1m 18s\tremaining: 15.1s\n",
      "482:\tlearn: 0.0183924\ttotal: 1m 18s\tremaining: 14.9s\n",
      "483:\tlearn: 0.0183921\ttotal: 1m 18s\tremaining: 14.7s\n",
      "484:\tlearn: 0.0183920\ttotal: 1m 18s\tremaining: 14.6s\n",
      "485:\tlearn: 0.0183918\ttotal: 1m 18s\tremaining: 14.4s\n",
      "486:\tlearn: 0.0183917\ttotal: 1m 18s\tremaining: 14.2s\n",
      "487:\tlearn: 0.0183916\ttotal: 1m 18s\tremaining: 14s\n",
      "488:\tlearn: 0.0183914\ttotal: 1m 18s\tremaining: 13.9s\n",
      "489:\tlearn: 0.0183912\ttotal: 1m 19s\tremaining: 13.7s\n",
      "490:\tlearn: 0.0183911\ttotal: 1m 19s\tremaining: 13.6s\n",
      "491:\tlearn: 0.0183910\ttotal: 1m 19s\tremaining: 13.4s\n",
      "492:\tlearn: 0.0183908\ttotal: 1m 19s\tremaining: 13.2s\n",
      "493:\tlearn: 0.0183907\ttotal: 1m 19s\tremaining: 13.1s\n",
      "494:\tlearn: 0.0183904\ttotal: 1m 19s\tremaining: 12.9s\n",
      "495:\tlearn: 0.0183902\ttotal: 1m 19s\tremaining: 12.7s\n",
      "496:\tlearn: 0.0183901\ttotal: 1m 19s\tremaining: 12.6s\n",
      "497:\tlearn: 0.0183897\ttotal: 1m 20s\tremaining: 12.4s\n",
      "498:\tlearn: 0.0183894\ttotal: 1m 20s\tremaining: 12.2s\n",
      "499:\tlearn: 0.0183893\ttotal: 1m 20s\tremaining: 12.1s\n",
      "500:\tlearn: 0.0183892\ttotal: 1m 20s\tremaining: 11.9s\n",
      "501:\tlearn: 0.0183890\ttotal: 1m 20s\tremaining: 11.7s\n",
      "502:\tlearn: 0.0183888\ttotal: 1m 20s\tremaining: 11.6s\n",
      "503:\tlearn: 0.0183886\ttotal: 1m 20s\tremaining: 11.4s\n",
      "504:\tlearn: 0.0183884\ttotal: 1m 20s\tremaining: 11.2s\n",
      "505:\tlearn: 0.0183883\ttotal: 1m 21s\tremaining: 11.1s\n",
      "506:\tlearn: 0.0183881\ttotal: 1m 21s\tremaining: 10.9s\n",
      "507:\tlearn: 0.0183878\ttotal: 1m 21s\tremaining: 10.7s\n",
      "508:\tlearn: 0.0183877\ttotal: 1m 21s\tremaining: 10.6s\n",
      "509:\tlearn: 0.0183874\ttotal: 1m 21s\tremaining: 10.4s\n",
      "510:\tlearn: 0.0183873\ttotal: 1m 21s\tremaining: 10.3s\n",
      "511:\tlearn: 0.0183872\ttotal: 1m 21s\tremaining: 10.1s\n",
      "512:\tlearn: 0.0183869\ttotal: 1m 22s\tremaining: 9.93s\n",
      "513:\tlearn: 0.0183868\ttotal: 1m 22s\tremaining: 9.76s\n",
      "514:\tlearn: 0.0183866\ttotal: 1m 22s\tremaining: 9.6s\n",
      "515:\tlearn: 0.0183865\ttotal: 1m 22s\tremaining: 9.43s\n",
      "516:\tlearn: 0.0183863\ttotal: 1m 22s\tremaining: 9.27s\n",
      "517:\tlearn: 0.0183860\ttotal: 1m 22s\tremaining: 9.1s\n",
      "518:\tlearn: 0.0183860\ttotal: 1m 22s\tremaining: 8.94s\n",
      "519:\tlearn: 0.0183857\ttotal: 1m 22s\tremaining: 8.78s\n",
      "520:\tlearn: 0.0183856\ttotal: 1m 23s\tremaining: 8.61s\n",
      "521:\tlearn: 0.0183855\ttotal: 1m 23s\tremaining: 8.45s\n",
      "522:\tlearn: 0.0183852\ttotal: 1m 23s\tremaining: 8.28s\n",
      "523:\tlearn: 0.0183852\ttotal: 1m 23s\tremaining: 8.12s\n",
      "524:\tlearn: 0.0183849\ttotal: 1m 23s\tremaining: 7.95s\n",
      "525:\tlearn: 0.0183847\ttotal: 1m 23s\tremaining: 7.79s\n",
      "526:\tlearn: 0.0183846\ttotal: 1m 23s\tremaining: 7.63s\n",
      "527:\tlearn: 0.0183844\ttotal: 1m 23s\tremaining: 7.46s\n",
      "528:\tlearn: 0.0183842\ttotal: 1m 23s\tremaining: 7.3s\n",
      "529:\tlearn: 0.0183841\ttotal: 1m 24s\tremaining: 7.14s\n",
      "530:\tlearn: 0.0183840\ttotal: 1m 24s\tremaining: 6.97s\n",
      "531:\tlearn: 0.0183840\ttotal: 1m 24s\tremaining: 6.81s\n",
      "532:\tlearn: 0.0183838\ttotal: 1m 24s\tremaining: 6.65s\n",
      "533:\tlearn: 0.0183837\ttotal: 1m 24s\tremaining: 6.48s\n",
      "534:\tlearn: 0.0183835\ttotal: 1m 24s\tremaining: 6.32s\n",
      "535:\tlearn: 0.0183834\ttotal: 1m 24s\tremaining: 6.16s\n",
      "536:\tlearn: 0.0183832\ttotal: 1m 24s\tremaining: 6s\n",
      "537:\tlearn: 0.0183830\ttotal: 1m 24s\tremaining: 5.84s\n",
      "538:\tlearn: 0.0183827\ttotal: 1m 25s\tremaining: 5.68s\n",
      "539:\tlearn: 0.0183824\ttotal: 1m 25s\tremaining: 5.52s\n",
      "540:\tlearn: 0.0183823\ttotal: 1m 25s\tremaining: 5.36s\n",
      "541:\tlearn: 0.0183821\ttotal: 1m 25s\tremaining: 5.2s\n",
      "542:\tlearn: 0.0183818\ttotal: 1m 25s\tremaining: 5.04s\n",
      "543:\tlearn: 0.0183818\ttotal: 1m 25s\tremaining: 4.87s\n",
      "544:\tlearn: 0.0183816\ttotal: 1m 25s\tremaining: 4.71s\n",
      "545:\tlearn: 0.0183815\ttotal: 1m 25s\tremaining: 4.55s\n",
      "546:\tlearn: 0.0183812\ttotal: 1m 25s\tremaining: 4.39s\n",
      "547:\tlearn: 0.0183811\ttotal: 1m 25s\tremaining: 4.23s\n",
      "548:\tlearn: 0.0183811\ttotal: 1m 26s\tremaining: 4.07s\n",
      "549:\tlearn: 0.0183809\ttotal: 1m 26s\tremaining: 3.92s\n",
      "550:\tlearn: 0.0183808\ttotal: 1m 26s\tremaining: 3.76s\n",
      "551:\tlearn: 0.0183806\ttotal: 1m 26s\tremaining: 3.6s\n",
      "552:\tlearn: 0.0183805\ttotal: 1m 26s\tremaining: 3.44s\n",
      "553:\tlearn: 0.0183804\ttotal: 1m 26s\tremaining: 3.28s\n",
      "554:\tlearn: 0.0183800\ttotal: 1m 26s\tremaining: 3.13s\n",
      "555:\tlearn: 0.0183799\ttotal: 1m 26s\tremaining: 2.97s\n",
      "556:\tlearn: 0.0183797\ttotal: 1m 26s\tremaining: 2.81s\n",
      "557:\tlearn: 0.0183796\ttotal: 1m 27s\tremaining: 2.65s\n",
      "558:\tlearn: 0.0183795\ttotal: 1m 27s\tremaining: 2.49s\n",
      "559:\tlearn: 0.0183794\ttotal: 1m 27s\tremaining: 2.34s\n",
      "560:\tlearn: 0.0183792\ttotal: 1m 27s\tremaining: 2.18s\n",
      "561:\tlearn: 0.0183791\ttotal: 1m 27s\tremaining: 2.02s\n",
      "562:\tlearn: 0.0183790\ttotal: 1m 27s\tremaining: 1.86s\n",
      "563:\tlearn: 0.0183789\ttotal: 1m 27s\tremaining: 1.71s\n",
      "564:\tlearn: 0.0183787\ttotal: 1m 27s\tremaining: 1.55s\n",
      "565:\tlearn: 0.0183786\ttotal: 1m 27s\tremaining: 1.4s\n",
      "566:\tlearn: 0.0183785\ttotal: 1m 27s\tremaining: 1.24s\n",
      "567:\tlearn: 0.0183785\ttotal: 1m 28s\tremaining: 1.08s\n",
      "568:\tlearn: 0.0183784\ttotal: 1m 28s\tremaining: 929ms\n",
      "569:\tlearn: 0.0183782\ttotal: 1m 28s\tremaining: 774ms\n",
      "570:\tlearn: 0.0183781\ttotal: 1m 28s\tremaining: 619ms\n",
      "571:\tlearn: 0.0183780\ttotal: 1m 28s\tremaining: 464ms\n",
      "572:\tlearn: 0.0183779\ttotal: 1m 28s\tremaining: 309ms\n",
      "573:\tlearn: 0.0183777\ttotal: 1m 28s\tremaining: 155ms\n",
      "574:\tlearn: 0.0183776\ttotal: 1m 28s\tremaining: 0us\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.8689422085799025\n"
     ]
    }
   ],
   "source": [
    "VotingRegressor1 = VotingRegressor(estimators=[('XGB', XGBRegressor(**XGB_params)), ('LGB', LGBMRegressor(**LGB_params)), ('CAT', CatBoostRegressor(**CAT_params))])\n",
    "\n",
    "VotingRegressor1.fit(X_train, y_train)\n",
    "y_pred = VotingRegressor1.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.57842254, 0.45622205, 0.45010377, ..., 0.62164899, 0.54878674,\n",
       "       0.52970055])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = VotingRegressor1.predict(df_test.drop(columns = 'id'))\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv = pd.DataFrame({'id': df_test.id, 'FloodProbability': submission})\n",
    "submission_csv.to_csv('submission6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
